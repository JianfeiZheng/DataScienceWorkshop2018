---
title: "Data Wrangling"
author: '[Hui Lin](http://scientistcafe.com) </br> </br> ![](http://scientistcafe.com/images/netlifylogo.png){width=15%}'
date: "`r Sys.Date()`"
output: 
  slidy_presentation: 
    footer: "http://scientistcafe.com"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)
```

## Outline

- Summarize data
    - `apply()`, `lapply()` and `sapply()` in base R
    - `ddply()` in `plyr` package
    - **`dplyr` package**
    
- Tidy and Reshape Data
    - `reshape2` package
    - `tidyr` package

## `dplyr` package

- Next iteration of `plyr` package
- Flexible grammar of data manipulation focusing on tools for working with data frames (hence the `d` in the name)
- It identifies the most important data manipulations and make they easy to use from R
- It performs faster for in-memory data by writing key pieces in C++ using `Rcpp`

## `dplyr` package

1. Display
1. Subset
1. Summarize
1. Create new variable
1. Merge

## Display

- `tbl_df()`: Convert the data to `tibble` 

```r
library(dplyr)
tbl_df(sim.dat)
```

- `glimpse()`: This is like a transposed version of `tbl_df()`

```r
glimpse(sim.dat)
```

## Subset

- Get rows with `income` more than 300000:

```r
filter(sim.dat, income >300000) %>%
  tbl_df()
```

- Here we meet a new operator `%>%`: "Pipe operator" 

## Pipe operator: `%>%`

- It pipes a value forward into an expression or function call
- What you get in the left operation will be the first argument or the only argument in the right operation.

```r
x %>% f(y) = f(x, y)
y %>% f(x, ., z) = f(x, y, z )
```

For example: `"Hello World" %>% substring(7, 11) %>% grepl("Wo", .)`

## Pipe operator: `%>%`

Look at the following code. Can you tell me what it does?

```r
ave_exp <- filter( 
  summarise(
    group_by( 
      filter(
        sim.dat, 
        !is.na(income)
      ), 
      segment
    ), 
    ave_online_exp = mean(online_exp), 
    n = n()
  ), 
  n > 200
) 
```
Now look at the identical code using "`%>%`":

```r
avg_exp <- sim.dat %>% 
 filter(!is.na(income)) %>% 
 group_by(segment) %>% 
 summarise( 
   ave_online_exp = mean(online_exp), 
   n = n() ) %>% 
  filter(n > 200)
```

## Let's read it

```r
avg_exp <- sim.dat %>% 
 filter(!is.na(income)) %>% 
 group_by(segment) %>% 
 summarise( 
   ave_online_exp = mean(online_exp), 
   n = n() ) %>% 
  filter(n > 200)
```

## Subset - select rows
 
- `distinct()`: a generalization of `unique()` from vector to data frame

```r
dplyr::distinct(sim.dat)
```

- `sample_frac()`: randomly select some rows with specified percentage. 
- `sample_n()`:randomly select rows with specified number.

```r
dplyr::sample_frac(sim.dat, 0.5, replace = TRUE) 
dplyr::sample_n(sim.dat, 10, replace = TRUE) 
```

- `slice()` will select rows by position:

```r
# It is equivalent to `sim.dat[10:15,]`
dplyr::slice(sim.dat, 10:15) 
```

- `top_n()`  select the order top n entries:

```r
dplyr::top_n(sim.dat,2,income)
```

## Subset - select columns

```r
# select by column name
dplyr::select(sim.dat,income,age,store_exp)

# select columns whose name contains a character string
dplyr::select(sim.dat, contains("_"))

# select columns whose name ends with a character string
# similar there is "starts_with"
dplyr::select(sim.dat, ends_with("e"))

# select columns Q1,Q2,Q3,Q4 and Q5
select(sim.dat, num_range("Q", 1:5)) 

# select columns whose names are in a group of names
dplyr::select(sim.dat, one_of(c("age", "income")))

# select columns between age and online_exp
dplyr::select(sim.dat, age:online_exp)

# select all columns except for age
dplyr::select(sim.dat, -age)
```

## Summarize

```r
dplyr::summarise(sim.dat, avg_online = mean(online_trans)) 
# apply function anyNA() to each column
# you can also assign a function vector such as: c("anyNA","is.factor")
dplyr::summarise_each(sim.dat, funs_(c("anyNA")))
```

- `group_by()` 

```r
sim.dat %>% group_by(segment) %>% summarise_each(funs_(c("anyNA")))
```

## Create new variable

- `mutate()`: compute and append one or more new columns:

```r
dplyr::mutate(sim.dat, total_exp = store_exp + online_exp)
```

- It will apply **window function** to the columns and return a column with the same length

```r
# min_rank=rank(ties.method = "min")
# mutate_each() means apply function to each column
dplyr::mutate_each(sim.dat, funs(min_rank)) 
```

-  `transmute()`: delete the original columns and only keep the new ones

```r
dplyr::transmute(sim.dat, total_exp = store_exp + online_exp) 
```

## Merge

```r
(x<-data.frame(cbind(ID=c("A","B","C"),x1=c(1,2,3))))
(y<-data.frame(cbind(ID=c("B","C","D"),y1=c(T,T,F))))
```

```r
# join to the left
# keep all rows in x
left_join(x,y,by="ID")
# get rows matched in both data sets
inner_join(x,y,by="ID")
# get rows in either data set
full_join(x,y,by="ID")
# filter out rows in x that can be matched in y 
# it doesn't bring in any values from y 
semi_join(x,y,by="ID")
# the opposite of  semi_join()
# it gets rows in x that cannot be matched in y
# it doesn't bring in any values from y
anti_join(x,y,by="ID")
```

## Tidy and Reshape Data 


-  "Tidy data" represent the information from a dataset as data frames where each row is an observation and each column contains the values of a variable

- convert data between the "wide" and the "long" format

- two commonly used packages for this kind of manipulations: `tidyr` and `reshape2`

## `reshape2` package

- reboot of previous package `reshape`
- main functions:
    1. `melt()` to convert an object into a molten data frame, i.e. from wide to long
    1. `dcast()` to cast a molten data frame into the shape you want, i.e. from long to wide

```r
# Take a baby subset of our exemplary clothes consumers data to illustrate:
(sdat<-sim.dat[1:5,1:6])
```

## `reshape2` example

- have a variable indicating the purchasing channel (i.e. online or in-store) and another column with the corresponding expense amount

```r
library(reshape2)
(mdat <- melt(sdat, measure.vars=c("store_exp","online_exp"),
              variable.name = "Channel",
              value.name = "Expense"))
```


- You can run a regression to study the effect of purchasing channel: 

```r
# Here we use all observations from sim.dat
mdat<-melt(sim.dat[,1:6], measure.vars=c("store_exp","online_exp"),
            variable.name = "Channel",
              value.name = "Expense")
fit<-lm(Expense~gender+house+income+Channel+age,data=mdat)
summary(fit)
```

## `reshape2` example

- compare the online and in store expense between male and female based on the house ownership

```r
dcast(mdat, house + gender ~ Channel, sum)
```

- left side : variables that you want to group by
- right side: variable you want to spread as columns

## `tidyr` package

- Get a baby set to illustrate:

```r
library(dplyr)
library(tidyr)
# practice functions we learnt before
sdat<-sim.dat[1:5,]%>%
  dplyr::select(age,gender,store_exp,store_trans)
sdat %>% tbl_df()
```

## `gather()`

- Analogous to `melt()` in `reshape2`

```r
library(tidyr)
msdat<-tidyr::gather(sdat,"variable","value",store_exp,store_trans)
msdat %>% tbl_df()
```

-  if we use the pipe operation,

```r
sdat%>%gather("variable","value",store_exp,store_trans)
```

- It is identical with the following code using `melt()`:

```r
library(reshape2)
melt(sdat, measure.vars=c("store_exp","store_trans"),
            variable.name = "variable",
              value.name = "value")
```

## `spread()`


```r
msdat %>% spread(variable,value)
```

##  `separate()` and `unite()`

```r
# You can use `sep=` 
# By default, it is "`_`"
sepdat<- msdat %>% 
  separate(variable,c("Source","Type"))
sepdat %>% tbl_df()
```

```r
sepdat %>% 
  unite("variable",Source,Type,sep="_")
```

## Hands-on

- https://github.com/happyrabbit/Talks/tree/master/2018_06_ShortCourse 